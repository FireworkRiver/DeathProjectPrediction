{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "def intRow(row):\n",
    "    temp = []\n",
    "    for t in row:\n",
    "        temp.append(int(t))\n",
    "    return temp\n",
    "\n",
    "def read_x(address):\n",
    "    reader = csv.reader(open(address))\n",
    "    x= [intRow(row) for row in reader]\n",
    "    return x\n",
    "\n",
    "def read_y(address):\n",
    "    reader = csv.reader(open(address))\n",
    "    list=[intRow(row) for row in reader]\n",
    "    y=sum(list,[])\n",
    "    return y\n",
    "\n",
    "X_0 = read_x('X.csv')\n",
    "Y = read_y('Y.csv')\n",
    "\n",
    "def NormalLine(row):\n",
    "    total = sum(row[-4:])\n",
    "    if total == 0:\n",
    "        total = 1\n",
    "    return [i/total for i in row]\n",
    "\n",
    "def differences(row):\n",
    "    total_list = row[-4:]\n",
    "    num_list = row[:-4]\n",
    "    differences_list = []\n",
    "    for i in range(int(len(num_list)/4)-1):\n",
    "        t1=num_list[i*4:(i+1)*4]\n",
    "        t2=num_list[(i+1)*4:(i+2)*4]\n",
    "        differences_list += [t2[j]-t1[j] for j in range(len(t1))]\n",
    "       \n",
    "    return num_list + differences_list +total_list\n",
    "\n",
    "X = [differences(NormalLine(row)) for row in X_0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "random_seed = 12345\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_random_train, x_test, y_random_train, y_test = train_test_split(X, Y, test_size=0.3, random_state=random_seed)\n",
    "\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "rus = RandomUnderSampler(random_state=random_seed)\n",
    "x_under_train, y_under_train = rus.fit_resample(x_random_train, y_random_train)\n",
    "\n",
    "from imblearn.over_sampling import SMOTE \n",
    "sm = SMOTE(random_state=random_seed)\n",
    "x_smote_train, y_smote_train = sm.fit_resample(x_random_train, y_random_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ZeroR underSampling dead recall 0.00 precision 0.00 f1_score 0.00\n",
      "ZeroR underSampling alive recall 1.00 precision 0.70 f1_score 0.82\n",
      "ZeroR smote dead recall 0.00 precision 0.00 f1_score 0.00\n",
      "ZeroR smote alive recall 1.00 precision 0.70 f1_score 0.82\n",
      "ZeroR random dead recall 0.00 precision 0.00 f1_score 0.00\n",
      "ZeroR random alive recall 1.00 precision 0.70 f1_score 0.82\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\envs\\NLP\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "D:\\Anaconda\\envs\\NLP\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "D:\\Anaconda\\envs\\NLP\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "def print_metrics(title,y_true,y_pre):\n",
    "    print(title+\" dead\",end = \" \")\n",
    "    print(\"recall %.2f\"%recall_score(y_true, y_pre),end =\" \")\n",
    "    print(\"precision %.2f\"%precision_score(y_true, y_pre),end=\" \")\n",
    "    print(\"f1_score %.2f\"%f1_score(y_true, y_pre))\n",
    "    \n",
    "    y_flip_true = [0 if i else 1 for i in y_true]\n",
    "    y_flip_pre = [0 if i else 1 for i in y_pre]\n",
    "    \n",
    "    print(title+\" alive\",end = \" \")\n",
    "    print(\"recall %.2f\"%recall_score(y_flip_true, y_flip_pre),end =\" \")\n",
    "    print(\"precision %.2f\"%precision_score(y_flip_true, y_flip_pre),end=\" \")\n",
    "    print(\"f1_score %.2f\"%f1_score(y_flip_true, y_flip_pre))\n",
    "\n",
    "y_pre_random_zeroR = [0 for i in range(len(y_test))]\n",
    "y_pre_under_zeroR = [0 for i in range(len(y_test))]\n",
    "y_pre_smote_zeroR = [0 for i in range(len(y_test))]\n",
    "\n",
    "print_metrics(\"ZeroR underSampling\",y_test,y_pre_under_zeroR)\n",
    "print_metrics(\"ZeroR smote\",y_test,y_pre_smote_zeroR)\n",
    "print_metrics(\"ZeroR random\",y_test,y_pre_random_zeroR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Knn underSampling dead recall 0.43 precision 0.58 f1_score 0.49\n",
      "Knn underSampling alive recall 0.86 precision 0.78 f1_score 0.82\n",
      "Knn smote dead recall 0.54 precision 0.51 f1_score 0.52\n",
      "Knn smote alive recall 0.78 precision 0.79 f1_score 0.79\n",
      "Knn random dead recall 0.24 precision 0.63 f1_score 0.35\n",
      "Knn random alive recall 0.94 precision 0.74 f1_score 0.83\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn_random = KNeighborsClassifier()\n",
    "knn_random.fit(x_random_train, y_random_train)\n",
    "y_pre_random_knn = knn_random.predict(x_test)\n",
    "\n",
    "knn_under = KNeighborsClassifier()\n",
    "knn_under.fit(x_under_train, y_under_train)\n",
    "y_pre_under_knn = knn_under.predict(x_test)\n",
    "\n",
    "knn_smote = KNeighborsClassifier()\n",
    "knn_smote.fit(x_smote_train, y_smote_train)\n",
    "y_pre_smote_knn = knn_smote.predict(x_test)\n",
    "\n",
    "print_metrics(\"Knn underSampling\",y_test,y_pre_under_knn)\n",
    "print_metrics(\"Knn smote\",y_test,y_pre_smote_knn)\n",
    "print_metrics(\"Knn random\",y_test,y_pre_random_knn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NB underSampling dead recall 0.44 precision 0.53 f1_score 0.48\n",
      "NB underSampling alive recall 0.83 precision 0.77 f1_score 0.80\n",
      "NB smote dead recall 0.49 precision 0.53 f1_score 0.51\n",
      "NB smote alive recall 0.81 precision 0.78 f1_score 0.80\n",
      "NB random dead recall 0.43 precision 0.54 f1_score 0.48\n",
      "NB random alive recall 0.84 precision 0.77 f1_score 0.81\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB,MultinomialNB,ComplementNB\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "GaussianNB_random = GaussianNB()\n",
    "GaussianNB_random.fit(x_random_train, y_random_train)\n",
    "y_pre_random_GNB = GaussianNB_random.predict(x_test)\n",
    "\n",
    "GaussianNB_under = GaussianNB()\n",
    "GaussianNB_under.fit(x_under_train, y_under_train)\n",
    "y_pre_under_GNB = GaussianNB_under.predict(x_test)\n",
    "\n",
    "GaussianNB_smote = GaussianNB()\n",
    "GaussianNB_smote.fit(x_smote_train, y_smote_train)\n",
    "y_pre_smote_GNB = GaussianNB_smote.predict(x_test)\n",
    "\n",
    "\n",
    "print_metrics(\"NB underSampling\",y_test,y_pre_under_GNB)\n",
    "print_metrics(\"NB smote\",y_test,y_pre_smote_GNB)\n",
    "print_metrics(\"NB random\",y_test,y_pre_random_GNB)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP underSampling dead recall 0.61 precision 0.47 f1_score 0.53\n",
      "MLP underSampling alive recall 0.70 precision 0.81 f1_score 0.75\n",
      "MLP smote dead recall 0.62 precision 0.48 f1_score 0.54\n",
      "MLP smote alive recall 0.70 precision 0.81 f1_score 0.75\n",
      "MLP random dead recall 0.30 precision 0.66 f1_score 0.41\n",
      "MLP random alive recall 0.93 precision 0.75 f1_score 0.83\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "MLP_under = MLPClassifier(activation='logistic',max_iter=300)\n",
    "MLP_under.fit(x_under_train, y_under_train)\n",
    "y_pre_under_MLP = MLP_under.predict(x_test)\n",
    "\n",
    "MLP_smote = MLPClassifier(activation='logistic',max_iter=300)\n",
    "MLP_smote.fit(x_smote_train, y_smote_train)\n",
    "y_pre_smote_MLP = MLP_smote.predict(x_test)\n",
    "\n",
    "MLP_random = MLPClassifier(activation='logistic',max_iter=300)\n",
    "MLP_random.fit(x_random_train, y_random_train)\n",
    "y_pre_random_MLP = MLP_random.predict(x_test)\n",
    "\n",
    "print_metrics(\"MLP underSampling\",y_test,y_pre_under_MLP)\n",
    "print_metrics(\"MLP smote\",y_test,y_pre_smote_MLP)\n",
    "print_metrics(\"MLP random\",y_test,y_pre_random_MLP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForeset underSampling dead recall 0.83 precision 0.51 f1_score 0.63\n",
      "RandomForeset underSampling alive recall 0.65 precision 0.90 f1_score 0.76\n",
      "RandomForeset smote dead recall 0.60 precision 0.53 f1_score 0.57\n",
      "RandomForeset smote alive recall 0.77 precision 0.82 f1_score 0.79\n",
      "RandomForeset random dead recall 0.40 precision 0.62 f1_score 0.49\n",
      "RandomForeset random alive recall 0.89 precision 0.77 f1_score 0.83\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf_under = RandomForestClassifier(random_state=random_seed)\n",
    "rf_under.fit(x_under_train, y_under_train)\n",
    "y_pre_under_rf = rf_under.predict(x_test)\n",
    "\n",
    "rf_smote = RandomForestClassifier(random_state=random_seed)\n",
    "rf_smote.fit(x_smote_train, y_smote_train)\n",
    "y_pre_smote_rf = rf_smote.predict(x_test)\n",
    "\n",
    "rf_random = RandomForestClassifier(random_state=random_seed)\n",
    "rf_random.fit(x_random_train, y_random_train)\n",
    "y_pre_random_rf = rf_random.predict(x_test)\n",
    "\n",
    "print_metrics(\"RandomForeset underSampling\",y_test,y_pre_under_rf)\n",
    "print_metrics(\"RandomForeset smote\",y_test,y_pre_smote_rf)\n",
    "print_metrics(\"RandomForeset random\",y_test,y_pre_random_rf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "input_length = len(x_random_train[0])\n",
    "callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    }
   ],
   "source": [
    "lstm = keras.Sequential()\n",
    "lstm.add(layers.LSTM(units=100, activation='tanh', return_sequences=True, input_shape=(input_length, 1)))\n",
    "lstm.add(layers.Dropout(0.5))\n",
    "lstm.add(layers.LSTM(units=50, activation='tanh', return_sequences=False))\n",
    "lstm.add(layers.Dropout(0.5))\n",
    "lstm.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "lstm.compile(optimizer='adam',\n",
    "            loss='binary_crossentropy',\n",
    "            metrics=['accuracy',tf.keras.metrics.Recall()])\n",
    "\n",
    "history_lstm = lstm.fit(np.array(x_under_train), np.array(y_under_train),validation_split=0.2,callbacks=[callback],epochs=20)\n",
    "plt.plot(history_lstm.history['accuracy'], label='Train')\n",
    "plt.plot(history_lstm.history['val_accuracy'], label='Validation')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.title('Training and validating accuracy')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "y_pre_under_lstm = (lstm.predict(x_test) > 0.5).astype(\"int32\").flatten()\n",
    "print_metrics(\"lstm underSampling\",y_test,y_pre_under_lstm.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "lstm3 = keras.Sequential()\n",
    "lstm3.add(layers.LSTM(units=100, activation='tanh', return_sequences=True, input_shape=(input_length, 1)))\n",
    "lstm3.add(layers.Dropout(0.5))\n",
    "lstm3.add(layers.LSTM(units=50, activation='tanh', return_sequences=False))\n",
    "lstm3.add(layers.Dropout(0.5))\n",
    "lstm3.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "lstm3.compile(optimizer='adam',\n",
    "            loss='binary_crossentropy',\n",
    "            metrics=['accuracy',tf.keras.metrics.Recall()])\n",
    "\n",
    "history_lstm3 = lstm3.fit(np.array(x_smote_train), np.array(y_smote_train),validation_split=0.2,callbacks=[callback],epochs=20)\n",
    "plt.plot(history_lstm.history['accuracy'], label='Train')\n",
    "plt.plot(history_lstm.history['val_accuracy'], label='Validation')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.title('Training and validating accuracy')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "y_pre_smote_lstm = (lstm3.predict(x_test) > 0.5).astype(\"int32\").flatten()\n",
    "print_metrics(\"lstm smote\",y_test,y_pre_smote_lstm.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "lstm2 = keras.Sequential()\n",
    "lstm2.add(layers.LSTM(units=100, activation='tanh', return_sequences=True, input_shape=(input_length, 1)))\n",
    "lstm2.add(layers.Dropout(0.2))\n",
    "lstm2.add(layers.LSTM(units=50, activation='tanh', return_sequences=False))\n",
    "lstm2.add(layers.Dropout(0.2))\n",
    "lstm2.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "\n",
    "lstm2.compile(optimizer='adam',\n",
    "            loss='binary_crossentropy',\n",
    "            metrics=['accuracy',tf.keras.metrics.Recall()])\n",
    "\n",
    "history_lstm2 = lstm2.fit(np.array(x_random_train), np.array(y_random_train),validation_split=0.2,callbacks=[callback], epochs=20)\n",
    "plt.plot(history_lstm2.history['accuracy'], label='train')\n",
    "plt.plot(history_lstm2.history['val_accuracy'], label='Validation')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.title('Training and validating accuracy')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "y_pre_random_lstm = (lstm2.predict(x_test) > 0.5).astype(\"int32\").flatten()\n",
    "print_metrics(\"lstm random\",y_test,y_pre_random_lstm.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "balance_pre_list = [y_pre_under_zeroR,\n",
    "                    y_pre_under_knn,\n",
    "                    y_pre_under_GNB,\n",
    "                    y_pre_under_MLP,\n",
    "                    y_pre_under_rf,\n",
    "                    y_pre_under_lstm.tolist()\n",
    "                    ]\n",
    "\n",
    "balance_2_pre_list = [y_pre_smote_zeroR,\n",
    "                      y_pre_smote_knn,\n",
    "                      y_pre_smote_GNB,\n",
    "                      y_pre_smote_MLP,\n",
    "                      y_pre_smote_rf,\n",
    "                      y_pre_smote_lstm.tolist()\n",
    "                      ]\n",
    "\n",
    "random_pre_list = [y_pre_random_zeroR,\n",
    "                   y_pre_random_knn,\n",
    "                   y_pre_random_GNB,\n",
    "                   y_pre_random_MLP,\n",
    "                   y_pre_random_rf,\n",
    "                   y_pre_random_lstm.tolist()\n",
    "                   ]\n",
    "\n",
    "test_list = [y_test,y_test,y_test]\n",
    "pre_list =[balance_pre_list, balance_2_pre_list,random_pre_list]\n",
    "\n",
    "def get_metrics(y_true,y_pre):    \n",
    "    result1=[recall_score(y_true, y_pre),\n",
    "             precision_score(y_true, y_pre),\n",
    "             f1_score(y_true, y_pre)]\n",
    "    \n",
    "    y_flip_true = [0 if i else 1 for i in y_true]\n",
    "    y_flip_pre = [0 if i else 1 for i in y_pre]\n",
    "    \n",
    "    result2=[recall_score(y_flip_true, y_flip_pre),\n",
    "             precision_score(y_flip_true, y_flip_pre),\n",
    "             f1_score(y_flip_true, y_flip_pre)]\n",
    "    \n",
    "    return result1,result2\n",
    "\n",
    "result= []\n",
    "for i in range(len(test_list)):\n",
    "    test_y = test_list[i]\n",
    "    pre_y_list = pre_list[i]\n",
    "    result_list1=[]\n",
    "    result_list2=[]\n",
    "    for pre_y in pre_y_list:\n",
    "        result1,result2 = get_metrics(test_y,pre_y)\n",
    "        result_list1+=result1\n",
    "        result_list2+=result2\n",
    "    result.append(result_list1)\n",
    "    result.append(result_list2)\n",
    "\n",
    "with open('./result/original_result.csv', 'w',newline='') as f:\n",
    "    print(\"writing..\")\n",
    "    writer = csv.writer(f)\n",
    "    for row in result:\n",
    "        writer.writerow(row)\n",
    "print(\"finish..\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "def intRow(row):\n",
    "    temp = []\n",
    "    for t in row:\n",
    "        temp.append(int(t))\n",
    "    return temp\n",
    "\n",
    "def read_x(address):\n",
    "    reader = csv.reader(open(address))\n",
    "    x= [intRow(row) for row in reader]\n",
    "    return x\n",
    "\n",
    "def read_y(address):\n",
    "    reader = csv.reader(open(address))\n",
    "    list=[intRow(row) for row in reader]\n",
    "    y=sum(list,[])\n",
    "    return y\n",
    "\n",
    "x_balance_test_0 = read_x('x_balance_test.csv')\n",
    "y_balance_test = read_y('y_balance_test.csv')\n",
    "x_balance_train_0 = read_x('x_balance_train.csv')\n",
    "y_balance_train = read_y('y_balance_train.csv')\n",
    "\n",
    "x_balance_2_test_0 = read_x('x_balance2_test.csv')\n",
    "y_balance_2_test = read_y('y_balance2_test.csv')\n",
    "x_balance_2_train_0 = read_x('x_balance2_train.csv')\n",
    "y_balance_2_train = read_y('y_balance2_train.csv')\n",
    "\n",
    "x_random_test_0 = read_x('x_random_test.csv')\n",
    "y_random_test = read_y('y_random_test.csv')\n",
    "x_random_train_0 = read_x('x_random_train.csv')\n",
    "y_random_train = read_y('y_random_train.csv')\n",
    "\n",
    "def NormalLine(row):\n",
    "    total = sum(row[-4:])\n",
    "    if total == 0:\n",
    "        total = 1\n",
    "    return [i/total for i in row]\n",
    "\n",
    "x_balance_test = [NormalLine(row) for row in x_balance_test_0]\n",
    "x_balance_train = [NormalLine(row) for row in x_balance_train_0]\n",
    "\n",
    "x_balance_2_test = [NormalLine(row) for row in x_balance_2_test_0]\n",
    "x_balance_2_train = [NormalLine(row) for row in x_balance_2_train_0]\n",
    "\n",
    "x_random_test =  [NormalLine(row) for row in x_random_test_0]\n",
    "x_random_train =  [NormalLine(row) for row in x_random_train_0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ZeroR balance dead recall 0.00 precision 0.00 f1_score 0.00\n",
      "ZeroR balance alive recall 1.00 precision 0.87 f1_score 0.93\n",
      "ZeroR balance_2 dead recall 0.00 precision 0.00 f1_score 0.00\n",
      "ZeroR balance_2 alive recall 1.00 precision 0.72 f1_score 0.84\n",
      "ZeroR random dead recall 0.00 precision 0.00 f1_score 0.00\n",
      "ZeroR random alive recall 1.00 precision 0.72 f1_score 0.84\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\envs\\NLP\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "D:\\Anaconda\\envs\\NLP\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "D:\\Anaconda\\envs\\NLP\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "def print_metrics(title,y_true,y_pre):\n",
    "    print(title+\" dead\",end = \" \")\n",
    "    print(\"recall %.2f\"%recall_score(y_true, y_pre),end =\" \")\n",
    "    print(\"precision %.2f\"%precision_score(y_true, y_pre),end=\" \")\n",
    "    print(\"f1_score %.2f\"%f1_score(y_true, y_pre))\n",
    "    \n",
    "    y_flip_true = [0 if i else 1 for i in y_true]\n",
    "    y_flip_pre = [0 if i else 1 for i in y_pre]\n",
    "    \n",
    "    print(title+\" alive\",end = \" \")\n",
    "    print(\"recall %.2f\"%recall_score(y_flip_true, y_flip_pre),end =\" \")\n",
    "    print(\"precision %.2f\"%precision_score(y_flip_true, y_flip_pre),end=\" \")\n",
    "    print(\"f1_score %.2f\"%f1_score(y_flip_true, y_flip_pre))\n",
    "\n",
    "y_pre_random_zeroR = [0 for i in range(len(y_random_test))]\n",
    "y_pre_balance_zeroR = [0 for i in range(len(y_balance_test))]\n",
    "y_pre_balance_2_zeroR = [0 for i in range(len(y_balance_2_test))]\n",
    "\n",
    "print_metrics(\"ZeroR balance\",y_balance_test,y_pre_balance_zeroR)\n",
    "print_metrics(\"ZeroR balance_2\",y_balance_2_test,y_pre_balance_2_zeroR)\n",
    "print_metrics(\"ZeroR random\",y_random_test,y_pre_random_zeroR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Knn balance dead recall 0.44 precision 0.29 f1_score 0.35\n",
      "Knn balance alive recall 0.84 precision 0.91 f1_score 0.87\n",
      "Knn balance_2 dead recall 0.42 precision 0.50 f1_score 0.46\n",
      "Knn balance_2 alive recall 0.84 precision 0.79 f1_score 0.82\n",
      "Knn random dead recall 0.23 precision 0.55 f1_score 0.33\n",
      "Knn random alive recall 0.93 precision 0.76 f1_score 0.84\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn_random = KNeighborsClassifier()\n",
    "knn_random.fit(x_random_train, y_random_train)\n",
    "y_pre_random_knn = knn_random.predict(x_random_test)\n",
    "\n",
    "knn_balance = KNeighborsClassifier()\n",
    "knn_balance.fit(x_balance_train, y_balance_train)\n",
    "y_pre_balance_knn = knn_balance.predict(x_balance_test)\n",
    "\n",
    "knn_balance_2 = KNeighborsClassifier()\n",
    "knn_balance_2.fit(x_balance_2_train, y_balance_2_train)\n",
    "y_pre_balance_2_knn = knn_balance_2.predict(x_balance_2_test)\n",
    "\n",
    "print_metrics(\"Knn balance\",y_balance_test,y_pre_balance_knn)\n",
    "print_metrics(\"Knn balance_2\",y_balance_2_test,y_pre_balance_2_knn)\n",
    "print_metrics(\"Knn random\",y_random_test,y_pre_random_knn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NB balance dead recall 0.46 precision 0.27 f1_score 0.34\n",
      "NB balance alive recall 0.81 precision 0.91 f1_score 0.86\n",
      "NB balance_2 dead recall 0.45 precision 0.48 f1_score 0.47\n",
      "NB balance_2 alive recall 0.82 precision 0.80 f1_score 0.81\n",
      "NB random dead recall 0.45 precision 0.50 f1_score 0.48\n",
      "NB random alive recall 0.83 precision 0.80 f1_score 0.81\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB,MultinomialNB,ComplementNB\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "GaussianNB_random = GaussianNB()\n",
    "GaussianNB_random.fit(x_random_train, y_random_train)\n",
    "y_pre_random_GNB = GaussianNB_random.predict(x_random_test)\n",
    "\n",
    "GaussianNB_balance = GaussianNB()\n",
    "GaussianNB_balance.fit(x_balance_train, y_balance_train)\n",
    "y_pre_balance_GNB = GaussianNB_balance.predict(x_balance_test)\n",
    "\n",
    "GaussianNB_balance_2 = GaussianNB()\n",
    "GaussianNB_balance_2.fit(x_balance_2_train, y_balance_2_train)\n",
    "y_pre_balance_2_GNB = GaussianNB_balance_2.predict(x_balance_2_test)\n",
    "\n",
    "\n",
    "print_metrics(\"NB balance\",y_balance_test,y_pre_balance_GNB)\n",
    "print_metrics(\"NB balance_2\",y_balance_2_test,y_pre_balance_2_GNB)\n",
    "print_metrics(\"NB random\",y_random_test,y_pre_random_GNB)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP balance dead recall 0.44 precision 0.29 f1_score 0.35\n",
      "MLP balance alive recall 0.84 precision 0.91 f1_score 0.87\n",
      "MLP balance_2 dead recall 0.60 precision 0.46 f1_score 0.52\n",
      "MLP balance_2 alive recall 0.73 precision 0.83 f1_score 0.78\n",
      "MLP random dead recall 0.18 precision 0.61 f1_score 0.28\n",
      "MLP random alive recall 0.96 precision 0.75 f1_score 0.84\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "MLP_balance = MLPClassifier(activation='logistic',max_iter=300)\n",
    "MLP_balance.fit(x_balance_train, y_balance_train)\n",
    "y_pre_balance_MLP = knn_balance.predict(x_balance_test)\n",
    "\n",
    "MLP_balance_2 = MLPClassifier(activation='logistic',max_iter=300)\n",
    "MLP_balance_2.fit(x_balance_2_train, y_balance_2_train)\n",
    "y_pre_balance_2_MLP = MLP_balance_2.predict(x_balance_2_test)\n",
    "\n",
    "MLP_random = MLPClassifier(activation='logistic',max_iter=300)\n",
    "MLP_random.fit(x_random_train, y_random_train)\n",
    "y_pre_random_MLP = MLP_random.predict(x_random_test)\n",
    "\n",
    "print_metrics(\"MLP balance\",y_balance_test,y_pre_balance_MLP)\n",
    "print_metrics(\"MLP balance_2\",y_balance_2_test,y_pre_balance_2_MLP)\n",
    "print_metrics(\"MLP random\",y_random_test,y_pre_random_MLP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForeset balance dead recall 0.83 precision 0.26 f1_score 0.40\n",
      "RandomForeset balance alive recall 0.65 precision 0.96 f1_score 0.78\n",
      "RandomForeset balance_2 dead recall 0.83 precision 0.49 f1_score 0.62\n",
      "RandomForeset balance_2 alive recall 0.67 precision 0.91 f1_score 0.77\n",
      "RandomForeset random dead recall 0.40 precision 0.60 f1_score 0.48\n",
      "RandomForeset random alive recall 0.90 precision 0.79 f1_score 0.84\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf_balance = RandomForestClassifier(random_state=0)\n",
    "rf_balance.fit(x_balance_train, y_balance_train)\n",
    "y_pre_balance_rf = rf_balance.predict(x_balance_test)\n",
    "\n",
    "rf_balance_2 = RandomForestClassifier(random_state=0)\n",
    "rf_balance_2.fit(x_balance_2_train, y_balance_2_train)\n",
    "y_pre_balance_2_rf = rf_balance_2.predict(x_balance_2_test)\n",
    "\n",
    "rf_random = RandomForestClassifier(random_state=0)\n",
    "rf_random.fit(x_random_train, y_random_train)\n",
    "y_pre_random_rf = rf_random.predict(x_random_test)\n",
    "\n",
    "print_metrics(\"RandomForeset balance\",y_balance_test,y_pre_balance_rf)\n",
    "print_metrics(\"RandomForeset balance_2\",y_balance_2_test,y_pre_balance_2_rf)\n",
    "print_metrics(\"RandomForeset random\",y_random_test,y_pre_random_rf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "input_length = len(x_balance_test[0])\n",
    "callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "100/100 [==============================] - 27s 129ms/step - loss: 0.6935 - accuracy: 0.4984 - recall: 0.6171 - val_loss: 0.6919 - val_accuracy: 0.4938 - val_recall: 0.0098\n",
      "Epoch 2/20\n",
      "100/100 [==============================] - 10s 100ms/step - loss: 0.6916 - accuracy: 0.5266 - recall: 0.5223 - val_loss: 0.6858 - val_accuracy: 0.6300 - val_recall: 0.7027\n",
      "Epoch 3/20\n",
      "100/100 [==============================] - 11s 113ms/step - loss: 0.6833 - accuracy: 0.5734 - recall: 0.6290 - val_loss: 0.6630 - val_accuracy: 0.6450 - val_recall: 0.6634\n",
      "Epoch 4/20\n",
      " 70/100 [====================>.........] - ETA: 2s - loss: 0.6761 - accuracy: 0.5848 - recall: 0.5933"
     ]
    }
   ],
   "source": [
    "lstm = keras.Sequential()\n",
    "lstm.add(layers.LSTM(units=100, activation='tanh', return_sequences=True, input_shape=(input_length, 1)))\n",
    "lstm.add(layers.Dropout(0.5))\n",
    "lstm.add(layers.LSTM(units=50, activation='tanh', return_sequences=False))\n",
    "lstm.add(layers.Dropout(0.5))\n",
    "lstm.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "lstm.compile(optimizer='adam',\n",
    "            loss='binary_crossentropy',\n",
    "            metrics=['accuracy',tf.keras.metrics.Recall()])\n",
    "\n",
    "history_lstm = lstm.fit(np.array(x_balance_train), np.array(y_balance_train),validation_split=0.2,callbacks=[callback],epochs=20)\n",
    "plt.plot(history_lstm.history['accuracy'], label='Train')\n",
    "plt.plot(history_lstm.history['val_accuracy'], label='Validation')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.title('Training and validating accuracy')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "y_pre_balance_lstm = (lstm.predict(x_balance_test) > 0.5).astype(\"int32\").flatten()\n",
    "print_metrics(\"lstm balance\",y_balance_test,y_pre_balance_lstm.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "lstm3 = keras.Sequential()\n",
    "lstm3.add(layers.LSTM(units=100, activation='tanh', return_sequences=True, input_shape=(input_length, 1)))\n",
    "lstm3.add(layers.Dropout(0.5))\n",
    "lstm3.add(layers.LSTM(units=50, activation='tanh', return_sequences=False))\n",
    "lstm3.add(layers.Dropout(0.5))\n",
    "lstm3.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "lstm3.compile(optimizer='adam',\n",
    "            loss='binary_crossentropy',\n",
    "            metrics=['accuracy',tf.keras.metrics.Recall()])\n",
    "\n",
    "history_lstm3 = lstm3.fit(np.array(x_balance_2_train), np.array(y_balance_2_train),validation_split=0.2,callbacks=[callback],epochs=20)\n",
    "plt.plot(history_lstm.history['accuracy'], label='Train')\n",
    "plt.plot(history_lstm.history['val_accuracy'], label='Validation')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.title('Training and validating accuracy')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "y_pre_balance_2_lstm = (lstm3.predict(x_balance_2_test) > 0.5).astype(\"int32\").flatten()\n",
    "print_metrics(\"lstm balance_2\",y_balance_2_test,y_pre_balance_2_lstm.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "lstm2 = keras.Sequential()\n",
    "lstm2.add(layers.LSTM(units=100, activation='tanh', return_sequences=True, input_shape=(input_length, 1)))\n",
    "lstm2.add(layers.Dropout(0.2))\n",
    "lstm2.add(layers.LSTM(units=50, activation='tanh', return_sequences=False))\n",
    "lstm2.add(layers.Dropout(0.2))\n",
    "lstm2.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "\n",
    "lstm2.compile(optimizer='adam',\n",
    "            loss='binary_crossentropy',\n",
    "            metrics=['accuracy',tf.keras.metrics.Recall()])\n",
    "\n",
    "history_lstm2 = lstm2.fit(np.array(x_random_train), np.array(y_random_train),validation_split=0.2,callbacks=[callback], epochs=20)\n",
    "plt.plot(history_lstm2.history['accuracy'], label='train')\n",
    "plt.plot(history_lstm2.history['val_accuracy'], label='Validation')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.title('Training and validating accuracy')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "y_pre_random_lstm = (lstm2.predict(x_random_test) > 0.5).astype(\"int32\").flatten()\n",
    "print_metrics(\"lstm random\",y_random_test,y_pre_random_lstm.tolist())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
